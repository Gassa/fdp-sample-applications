# FDP Sample Application for Integration with Analytics Pipeline

The application uses the distributed master/worker pattern and is implemented using Akka clustering.

To run the application, the recommended way is to run the processes in separate JVMs. The application consists of the following components that can be run together ina single JVM or separate JVMs:

* Workers - they are not part of the cluster but can be used to distribute work by the front end
* Front End - generates work and sends to the master / backend
* Backend / Master - Takes work from front end and distributes amongst workers 

## Steps to run the application

* Start backend (`2551` is a seed node for the cluster)

`$ sbt "runMain com.lightbend.fdp.sample.Main --port 2551"`

* Start another backend (`2552` is a seed node for the cluster). Need to run both the seed nodes for the cluster.

`$ sbt "runMain com.lightbend.fdp.sample.Main --port 2552"`

* Start frontend (Port numbers should be between `3000` and `3999`)

`$ sbt "runMain com.lightbend.fdp.sample.Main --port 3001"`

* Start worker (Start instances of workers to to perform the job)

`$ sbt "runMain com.lightbend.fdp.sample.Main --port 0"`

## Control Points and Command Line Arguments

The workers execute a job which is computing the sum of the factorials of the elements of a randomly generated list of integers. The job is generated by the *frontend* process and has the following *control points* to vary the load on the system:

```
akka {
  job {
    ## maximum size that the randomly generated list of integers can have
    max-list-size = 40

    ## maximum value that an element of the list can have
    max-list-element-value = 5000

    ## after this duration a job is considered to have timed out
    ## tune this depending on the computational expense of the job
    job-timeout = 20 seconds

    ## the duration after which the front end will fork the next job
    ## This helps control the throttle of job production
    job-schedule-frequency = 200 millis
  }
}
```
  
The default values as mentioned above are there in `application.conf`. The defaults can be overridden by using `-Dname=value` pattern just as in other Akka applications. For convenience, arguments can also be specified in the command line. 

Here's a brief outline of the various options to specify arguments through command line or use the ones through config file:

Here's how the configuration works. Consider the case of a setting of `job-timeout`:

`$ sbt "runMain com.lightbend.fdp.sample.Main --port 2551"`

* The value of `job-timeout` is picked from `application.conf`. Throws exception if not found.

`$ sbt "runMain com.lightbend.fdp.sample.Main --port 2551 --job-timeout 70s"`

* The value of `job-timeout` is picked from the command line argument.

`$ sbt -Dakka.job.job-timeout=50s  "runMain com.lightbend.fdp.sample.Main --port 2551"`

* The value of `job-timeout` from `application.conf` is overridden with the one supplied using `-D`.

`$ sbt -Dakka.job.job-timeout=50s  "runMain com.lightbend.fdp.sample.Main --port 2551 --job-timeout 70s"`

* The value of `job-timeout` is picked from the command line argument.


The way to increase the load on the system is to submit more CPU intensive jobs. This can be done by changing the control points during startup of the front end process e.g. generating longer lists, generating lists of higher valued integers or a combination of both of them. Also the overall load of the system can be increased by generating jobs more frequently (decreasing the duration in `job-schedule-frequency`).

## Scaling Actions

In the steady state when jobs are generated and consumed, the application reports statistics of throughput and the number of workers used. The file is generated in `/tmp/stats.txt`. It's a comma delimited file with the following elements:

* number of jobs completed in last 1 minute
* number of workers used
* total number of jobs pending
* total number of jobs in progress
* total number of jobs accepted by master
* total number of jobs done

If from the above statistics we see that the throughput needs to be improved, we need to invoke the scaling actions. 2 *scaling actions* are suggested:

* increase number of workers - This will work if the current rate of job generation exceeds the capacity of the workers to handle
* increase number of front end processes - This will work if the current set of workers is idle and needs more jobs to generate better throughput

